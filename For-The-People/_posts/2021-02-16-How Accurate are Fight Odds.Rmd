---
title: "How Accurate are Fight Odds?"
author: "Aggression to the Mean"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: md_document
category: arts
---

```{r setup, include=FALSE}
# Figure path on disk = base.dir + fig.path
# Figure URL online = base.url + fig.path
knitr::opts_knit$set(base.dir = "/Users/Shared/AttM/", base.url="/AttM/")
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.path = "rmd_images/2021-02-16-how_accurate_are_fight_odds/")

# ------

# knitr::opts_chunk$set(warning = FALSE, message = FALSE, root.dir = "/Users/Shared/AttM")
# setwd("/Users/Shared/AttM")
```

 <br>

# Introduction

In a another post called [Understanding Fight Odds](https://aggression-to-the-mean.github.io/AttM/for-the-people/arts/2021/02/16/Understanding-Fight-Odds.html), I described what the fight odds (specifically American Odds) signify and how to interpret them. I also briefly explored the question "Are fight odds accurate?" by looking at the relationship between the actual Probability of Victory of fighters and the Implied Probability of the fight odds that they were given (we'll review these data later).  

I had a smart ass friend point out that the trends found in the average relationship between actual Probability of Victory and Implied Probability may break down if we look at the relationships on a smaller time frame (e.g. year-to-year). This is actually a great point and will be, in part, the focus of this post.  Specifically, I will look at how the performance of the odds varies across years and across methods of victory (i.e. TKO, Decision, etc.).   

 <br>
 
### Dataset - Historical Data of UFC Fight Odds 

```{r include = F, echo = F}
## ------------------------------------------------------------------------------------------------------
library(tidyverse)


## ------------------------------------------------------------------------------------------------------
load("./Datasets/df_master.RData")


## ------------------------------------------------------------------------------------------------------
summary(df_master)


## ------------------------------------------------------------------------------------------------------
df_master$NAME = as.factor(df_master$NAME)
df_master$Date = as.Date(df_master$Date)
df_master$Event = as.factor(df_master$Event)
df_master$City= as.factor(df_master$City)
df_master$State = as.factor(df_master$State)
df_master$Country = as.factor(df_master$Country)
df_master$FightWeightClass = as.factor(df_master$FightWeightClass)
df_master$Method = as.factor(df_master$Method)
df_master$Winner_Odds = as.numeric(df_master$Winner_Odds)
df_master$Loser_Odds = as.numeric(df_master$Loser_Odds)
df_master$fight_id = as.factor(df_master$fight_id)
df_master$Sex = as.factor(df_master$Sex)
df_master$Result = as.factor(df_master$Result)
df_master$FighterWeightClass = as.factor(df_master$FighterWeightClass)

## ------------------------------------------------------------------------------------------------------
df_odds = df_master
rm(df_master)


## ------------------------------------------------------------------------------------------------------
df_odds %>%
  dplyr::filter(
    (Method != "DQ") & (Method != "Overturned")
    , is.finite(Winner_Odds)
    , is.finite(Loser_Odds)
  ) -> df_odds


## ------------------------------------------------------------------------------------------------------
df_odds %>%
  dplyr::select(-c(FighterWeight:SUBA)) %>%
  spread(Result, NAME) -> df_odds_short

## ------------------------------------------------------------------------------------------------------
df_odds_short %>%
  dplyr::filter(Winner_Odds != Loser_Odds) %>%  # filter out equal odds
  dplyr::mutate(
    Favorite_was_Winner = ifelse(Winner_Odds < Loser_Odds, T, F)
    , Favorite_Unit_Profit = ifelse(Favorite_was_Winner, Winner_Odds - 1, -1)
    , Underdog_Unit_Profit = ifelse(!Favorite_was_Winner, Winner_Odds - 1, -1)
  ) -> df_odds_short

## ------------------------------------------------------------------------------------------------------
df_odds_short %>% dplyr::mutate(
  Favorite_Probability = ifelse(Favorite_was_Winner, 1/Winner_Odds, 1/Loser_Odds)
  , Underdog_Probability = ifelse(!Favorite_was_Winner,  1/Winner_Odds, 1/Loser_Odds)
) -> df_odds_short


## ------------------------------------------------------------------------------------------------------
df_odds_short %>%
  dplyr::mutate(
    Total_Probability = Favorite_Probability + Underdog_Probability
    , Overround = Total_Probability - 1
  ) -> df_odds_short

```

Using data science tools such as web scraping, I have obtained a dataset with fight odds information regarding the majority of the UFC fights that occurred between 2013 and present.   

```{r include== F, echo = F}
nfights = nrow(df_odds_short)
nevents = length(unique(df_odds_short$Event))
earliest_date = format(min(df_odds_short$Date), '%B %d, %Y')
latest_date = format(max(df_odds_short$Date), '%B %d, %Y')
```

In particular, the dataset consists of `r nfights` UFC fights from `r nevents` UFC events, spanning from `r earliest_date` to `r latest_date`.  

Among other things, the dataset lists the best odds for each fighter around the time of their fight, as well as the winner of each fight.  

 <br>

# Let's Review! Are Fight Odds "Accurate"?

```{r echo = F}
# add year as variable
df_odds_short %>%
  dplyr::mutate(
    Year = format(Date,"%Y")
  ) -> df_odds_short

df_odds_short %>%
  dplyr::mutate(
    Adjusted_Favorite_Probability = Favorite_Probability - Overround/2
    , Adjusted_Underdog_Probability = Underdog_Probability - Overround/2
    , Adjusted_Total_Probability = Adjusted_Favorite_Probability + Adjusted_Underdog_Probability
  ) -> df_odds_short

gauge_over_performance = function(num_bin = 10, min_bin_size = 30, variable = NULL) {

  # get bins for Favorite
  df_odds_short$Favorite_Probability_Bin = cut(df_odds_short$Adjusted_Favorite_Probability, num_bin)
  # get bins for Underdog
  df_odds_short$Underdog_Probability_Bin = cut(df_odds_short$Adjusted_Underdog_Probability, num_bin)

  if (is.null(variable)) {
    # check over/under performance for Favorites
    df_odds_short %>%
      dplyr::group_by(Favorite_Probability_Bin) %>%
      dplyr::summarise(
        Prop_of_Victory = mean(Favorite_was_Winner)
        , Size_of_Bin = length(Favorite_was_Winner)
        , ROI = mean(Favorite_Unit_Profit)
      ) -> fav_perf
  } else {

    # create dummy variable for function
    df_odds_short$Dummy = df_odds_short[
      ,which(colnames(df_odds_short) == sprintf("%s", variable))
    ]

    # check over/under performance for Favorites
    df_odds_short %>%
      dplyr::group_by(Favorite_Probability_Bin, Dummy) %>%
      dplyr::summarise(
        Prop_of_Victory = mean(Favorite_was_Winner)
        , Size_of_Bin = length(Favorite_was_Winner)
        , ROI = mean(Favorite_Unit_Profit)
      ) -> fav_perf
  }

  # extract bins
  fav_labs <- as.character(fav_perf$Favorite_Probability_Bin)
  fav_bins = as.data.frame(
    cbind(
      lower = as.numeric( sub("\\((.+),.*", "\\1", fav_labs) )
      , upper = as.numeric( sub("[^,]*,([^]]*)\\]", "\\1", fav_labs) )
    )
  )
  # get value in middle of bin
  fav_bins %>% dplyr::mutate(mid_bin = (lower + upper)/2 ) -> fav_bins
  # add mid bin column
  fav_perf$Mid_Bin = fav_bins$mid_bin
  # add Over performance column
  fav_perf %>% dplyr::mutate(Over_Performance = Prop_of_Victory - Mid_Bin) -> fav_perf


  if (is.null(variable)) {

    # plot over/under performance
    fav_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin*100, y=Over_Performance * 100))+
      geom_point()+
      geom_smooth(se=F)+
      geom_hline(yintercept = 0, linetype = "dotted")+
      ylab("Over Performance (%)")+
      xlab("Adjusted Implied Probability (%)")+
      ggtitle("Favorites")+
      theme(text = element_text(size = 16))->gg
    print(gg)

    # plot over/under performance
    fav_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin * 100, y=Prop_of_Victory*100))+
      geom_point()+
      geom_smooth(se=F)+
      ylab("Probability of Victory (%)")+
      xlab("Adjusted Implied Probability (%)")+
      geom_abline(slope=1, intercept=0, linetype = "dotted")+
      ggtitle("Favorites")+
      theme(text = element_text(size = 16))->gg
    print(gg)

    # # plot ROI - only real difference is scale along y axis
    # fav_perf %>%
    #   dplyr::filter(Size_of_Bin >= min_bin_size) %>%
    #   ggplot(aes(x=Mid_Bin*100, y= ROI* 100))+
    #   geom_point()+
    #   geom_smooth(se=F)+
    #   geom_hline(yintercept = 0, linetype = "dotted")+
    #   ylab("ROI (%)")+
    #   xlab("Adjusted Implied Probability (%)")+
    #   ggtitle("Favorites") -> gg
    # print(gg)

  } else {
    # plot over/under performance
    fav_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin*100, y=Over_Performance * 100, group=Dummy, colour = Dummy))+
      geom_point()+
      geom_smooth(se=F)+
      geom_hline(yintercept = 0, linetype = "dotted")+
      ylab("Over Performance (%)")+
      xlab("Adjusted Implied Probability (%)")+
      ggtitle("Favorites")+
      labs(color=sprintf("%s", variable))+
      theme(text = element_text(size = 16)) -> gg
    print(gg)

    # # plot ROI - only real difference is scale along y axis
    # fav_perf %>%
    #   dplyr::filter(Size_of_Bin >= min_bin_size) %>%
    #   ggplot(aes(x=Mid_Bin*100, y= ROI* 100, group=Dummy, colour = Dummy))+
    #   geom_point()+
    #   geom_smooth(se=F)+
    #   geom_hline(yintercept = 0, linetype = "dotted")+
    #   ylab("ROI (%)")+
    #   xlab("Adjusted Implied Probability (%)")+
    #   ggtitle("Favorites")+
    #   labs(color=sprintf("%s", variable)) -> gg
    # print(gg)
  }


  if (is.null(variable)) {

    # check over/under performance for Underdogs
    df_odds_short %>%
      dplyr::group_by(Underdog_Probability_Bin) %>%
      dplyr::summarise(
        Prop_of_Victory = mean(!Favorite_was_Winner)
        , Size_of_Bin = length(!Favorite_was_Winner)
        , ROI = mean(Underdog_Unit_Profit)
      ) -> under_perf

  } else {

    # check over/under performance for Underdogs
    df_odds_short %>%
      dplyr::group_by(Underdog_Probability_Bin, Dummy) %>%
      dplyr::summarise(
        Prop_of_Victory = mean(!Favorite_was_Winner)
        , Size_of_Bin = length(!Favorite_was_Winner)
        , ROI = mean(Underdog_Unit_Profit)
      ) -> under_perf
  }

  # extract bins
  under_labs <- as.character(under_perf$Underdog_Probability_Bin)
  under_bins = as.data.frame(
    cbind(
      lower = as.numeric( sub("\\((.+),.*", "\\1", under_labs) )
      , upper = as.numeric( sub("[^,]*,([^]]*)\\]", "\\1", under_labs) )
    )
  )
  # get value in middle of bin
  under_bins %>% dplyr::mutate(mid_bin = (lower + upper)/2 ) -> under_bins
  # add mid bin column
  under_perf$Mid_Bin = under_bins$mid_bin
  # add Over performance column
  under_perf %>% dplyr::mutate(Over_Performance = Prop_of_Victory - Mid_Bin) -> under_perf


  if (is.null(variable)) {
    # plot over/under performance
    under_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin*100, y=Over_Performance * 100))+
      geom_point()+
      geom_smooth(se=F)+
      geom_hline(yintercept = 0, linetype = "dotted")+
      ylab("Over Performance (%)")+
      xlab("Adjusted Implied Probability (%)")+
      ggtitle("Underdogs")+
      theme(text = element_text(size = 16))->gg
    print(gg)

    # plot over/under performance
    under_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin * 100, y=Prop_of_Victory*100))+
      geom_point()+
      geom_smooth(se=F)+
      ylab("Probability of Victory (%)")+
      xlab("Adjusted Implied Probability (%)")+
      geom_abline(slope=1, intercept=0, linetype = "dotted")+
      ggtitle("Underdogs")+
      theme(text = element_text(size = 16))->gg
    print(gg)

    # under_perf %>%
    #   dplyr::filter(Size_of_Bin >= min_bin_size) %>%
    #   ggplot(aes(x=Mid_Bin*100, y=ROI * 100))+
    #   geom_point()+
    #   geom_smooth(se=F)+
    #   geom_hline(yintercept = 0, linetype = "dotted")+
    #   ylab("ROI (%)")+
    #   xlab("Adjusted Implied Probability (%)")+
    #   ggtitle("Underdogs")-> gg
    # print(gg)

  } else {

    # plot over/under performance
    under_perf %>%
      dplyr::filter(Size_of_Bin >= min_bin_size) %>%
      ggplot(aes(x=Mid_Bin*100, y=Over_Performance * 100, group=Dummy, colour = Dummy))+
      geom_point()+
      geom_smooth(se=F)+
      geom_hline(yintercept = 0, linetype = "dotted")+
      ylab("Over Performance (%)")+
      xlab("Adjusted Implied Probability (%)")+
      ggtitle("Underdogs")+
      labs(color=sprintf("%s", variable))+
      theme(text = element_text(size = 16)) -> gg
    print(gg)

    # under_perf %>%
    #   dplyr::filter(Size_of_Bin >= min_bin_size) %>%
    #   ggplot(aes(x=Mid_Bin*100, y=ROI * 100, group=Dummy, colour = Dummy))+
    #   geom_point()+
    #   geom_smooth(se=F)+
    #   geom_hline(yintercept = 0, linetype = "dotted")+
    #   ylab("ROI (%)")+
    #   xlab("Adjusted Implied Probability (%)")+
    #   ggtitle("Underdogs")+
    #   labs(color=sprintf("%s", variable)) -> gg
    # print(gg)
  }
  
  # process to return()
  under_perf$Is_Fav = F
  under_perf %>%
    rename(Probability_Bin = Underdog_Probability_Bin) -> under_perf
  
  fav_perf$Is_Fav = T
  fav_perf %>%
    rename(Probability_Bin = Favorite_Probability_Bin) -> fav_perf
  
  return(rbind(fav_perf, under_perf))

}

```

The below graphs, analyzed in greater detail in a another post, showcase the relationship between the actual Probability of Victory of fighters and the Adjusted Implied Probability of the fight odds that they were given.  

Compared to my another post, I added a couple graphs that allows us to look at the same data from a different perspective. I have added graphs that represent Over Performance instead of Probability of Victory on the y-axis. Over Performance is simply the difference between the black dots (or the blue lines) and the diagonal dotted line from the Probability of Victory graphs. If a black dot is above the dotted line, fighters in that odds bin overperformed. Conversely, if a black dot is below the dotted line, fighters in that odds bin underperformed.  

 <br>

```{r echo = F}
var_null = gauge_over_performance(num_bin = 10, min_bin_size = 100, variable = NULL)
```

 <br>
 
As discussed in a another post, the odds do a pretty good job of predicting who will win across multiple fights, but do appear to convey some bias whereby underdogs overperform in close match-ups whereas favorites overperform in disperate pairings. 
 
Now, let's break down the Over Performance graphs by year to see if the aforementioned bias holds...

 <br>
 
# Yearly Odds Performance

Oh boy. The graphs look like rainbow speghetti thrown at a wall.  

Part of the reason the colored lines and dots look nearly randomly dispersed is that the amount of data going into any particular estimate (dot or line) is reduced. In the previous graphs, we had fight data from 2013 to 2020 going into 7-8 point estimates (dots). Now, that same amount of data has to contribute to many more point estimates (dots). The result is many unstable estimates as we see below. Indeed, averaging over many data, as we did in the above graphs, almost always makes the data look much nicer / smoother.  

 <br>

```{r echo=F}
var_year = gauge_over_performance(num_bin = 10, min_bin_size = 30, variable = "Year")
```

 <br>

So what do we make of this? Well, had you tried to exploit the aforementioned bias by betting on underdogs with Implied Probabilities around 37%, you would have probably made some money most years, with the exception of 2016 and 2020.    

**Does that mean that you should start putting money down on moderate underdogs? Not quite. Although the average Over Performance across many years does point to an overarching trend, it is unclear that you could expect to get a reasonable return on investment by betting solely on moderate underdogs on any given year. The trend just does not seem that strong or stable.**

 <br>

### Descriptive vs. Inferential Statistics

The above graphs are what most statisticians/scientists would refer to as Descriptive Statistics.  
Descriptive Statistics involve summarizing the data graphically, as well as looking at averages and measures of variability (like standard deviations).   

Inferential Statistics involve using statistical models to generalize findings from the data, quantify uncertainty (e.g. how credible are these findings?), and make predictions.  

In our case, we could use Inferential Statistics to determine the credibility of the aforementioned bias in the fight odds (i.e. is the bias "real" or just a statistical artifact). Perhaps more importantly, we could use Inferential Statistics to predict how well the odds will perform in future match-ups and determine our confidence in those predictions.   

 <br>
 
# Relationship between Odds and Method of Victory

The below graphs display how the Over Performance curves differ based on the method of victory.  

Looking at the Favorites graph, it is clear that favorites grossly underperform when fights go to Split Decisions (S-DEC). The reason for this may be that split decisions are basically toss-ups (50/50). Therefore, if a favorite makes it to a split-decision, they by definition have less of a chance of winning than the odds would have implied.  

Sticking with the Favorites, it looks like favorites generally overperform when fights go to Unanimous Decisions (U-DEC). This seems intuitive since the favoured fighter is typically considered the "better" fighter in some holistic sense. Therefore, when the fight goes the distance, they should be more likely to have out-pointed their opponent (even when taking the odds into account).    

Conversely, looking at the Underdogs graph, underdogs may be more likely to overperform than favorites when the fight ends with a finish - TKO or Submission (SUB).  Digging a bit deeper, it seems like moderate underdogs (~35%-40%) overperform when the fight ends in a submission, whereas prohibitive underdogs (<20%) overperform when the fight ends in a KO/TKO. The latter finding plays into our intuition of a "puncher's chance".  

 <br>

```{r echo=F}
odds_perf_by_method = gauge_over_performance(num_bin = 5, min_bin_size = 30, variable = "Method")
```

 <br>
 
### Do Odds Predict Method of Victory?

Now that we have assessed how overperformance varies with the method of victory, as a last order of business, let's see how the odds predict the method of victory. Are certain fight outcomes (e.g. KO vs. Unanimous Decisions) more likely if a fighter is heavily favored over another?  

The below graphs allow us to answer this question by plotting the relative probability of various methods of victory as a function of the fight odds.  

It looks like if the odds are fairly close (30%-70% of victory), the relative probabilities of the method of victory look something like:  
- KO/TKO: ~30%  
- Unanimous Decision: ~40%  
- Submission: 15%-20%   
- Split Decision: 10%-15%  

However, when the odds become more disperate - big favorites (>75%) and big underdogs (<25%) - the relative probabilities of the method of victory look a bit different:   
- KO/TKO: ~40%  
- Unanimous Decision: ~35%  
- Submission: >20%  
- Split Decision: ~5%

 <br>
 
```{r echo=F}
odds_perf_by_method %>%
  group_by(Is_Fav, Mid_Bin) %>%
  summarise(Total_Count = sum(Size_of_Bin)) -> total_count

odds_perf_by_method %>%
  group_by(Is_Fav, Mid_Bin, Dummy) %>%
  summarise(Count= Size_of_Bin) -> single_count

method_count_by_odds = merge(single_count, total_count)
method_count_by_odds %>%
  dplyr::mutate(Method_Prop = Count / Total_Count ) -> method_count_by_odds

method_count_by_odds %>%
  dplyr::filter(Is_Fav == T) %>%
  ggplot(aes(x=Mid_Bin*100, y=Method_Prop*100, group = Dummy, color=Dummy))+
  geom_point()+
  geom_smooth(se=F)+
  ylab("Probability of Method (%)")+
  xlab("Implied Probability (%)")+
  ggtitle("Favorites")+
  labs(color="Method")+
  theme(text = element_text(size = 16))

method_count_by_odds %>%
  dplyr::filter(Is_Fav == F) %>%
  ggplot(aes(x=Mid_Bin*100, y=Method_Prop*100, group = Dummy, color=Dummy))+
  geom_point()+
  geom_smooth(se=F)+
  ylab("Probability of Method (%)")+
  xlab("Implied Probability (%)")+
  ggtitle("Underdogs")+
  labs(color="Method")+
  theme(text = element_text(size = 16))
```
 
 <br>
 
**The primary take-away from the above graphs should seem fairly intuitive: bad match-ups (big underdog and big favorite) have a greater probability of ending as a finish (i.e. TKO or SUB) than do closer match-ups (moderate underdog and moderate favorite).**

 <br>

# Conclusion 

The apparent overarching bias whereby moderate underdogs overperform varies a lot from year to year.  

Also, favorites generally tend to overperform when fights go to decision, unless it goes to split decision, in which case the favorites drastically underperform with respect to the odds.  On the flip side, there may be something to this idea of big underdogs having a "puncher's chance" since they tend to overperform when the fight ends in a KO/TKO.  

Finally, bad match-ups (big underdog and big favorite) are less likely to end in a decision / more likely to end in a finish (i.e KO/TKO or Submission).   


